\chapter{Introduction}


\section{Motivation and Research Context}
Interest in physiological computing has increased \textemdash, leveraging bodily signals to assess internal states in health monitoring, affective computing, and human-computer interaction. A key physiological signal is the Galvanic Skin Response (GSR) or electrodermal activity. GSR measures changes in the skin's electrical conductance due to sweat gland activity, influenced by the sympathetic nervous system. These involuntary changes reflect emotional arousal and stress, making GSR a widely accepted indicator of autonomic nervous system activity \cite{ref1}. GSR is used in clinical psychology (e.g., biofeedback therapy and polygraph tests) and in user experience research, where it can reveal unconscious stress or emotional responses. Moreover, modern smartwatches from Apple and Samsung incorporate sensors for stress monitoring via GSR or related metrics. This trend reflects the growing interest in utilising physiological signals like GSR in everyday contexts.

Despite GSR's value, traditional measurement requires skin-contact electrodes (usually attached to fingers or palms with conductive gel) \cite{ref3}. This method is obtrusive: wires and electrodes restrict movement, and long-term use can cause discomfort or skin irritation \cite{ref3}. These limitations make it difficult to use GSR outside the lab. Consequently, contactless GSR measurement has become an appealing research direction \cite{ref4}. The idea is to infer GSR (or the underlying psychophysiological arousal) using remote sensors that require no physical contact with the user. For example, thermal infrared cameras detect subtle skin temperature changes from blood flow and perspiration, offering a proxy for stress responses \cite{ref5}.

Facial thermal imaging is a promising complement in emotion research, as stress and thermoregulation are connected (e.g., perspiration causes cooling) \cite{ref5}. Similarly, high-resolution RGB video combined with advanced computer vision can non-invasively capture other physiological signals. Prior work shows that heart rate and breathing can be measured from video of a person's face or body \cite{ref6}. These developments suggest that multi-modal sensing \textemdash combining traditional biosensors with imaging \textemdash could enable contactless physiological monitoring in the near future. Affective computing research reveals that integrating multiple modalities (e.g., GSR, heart rate, facial thermal data) can more effectively capture emotional or stress states \cite{ref1}.

Challenges remain. A key gap is the absence of an integrated platform to synchronise diverse data streams. Most studies have tackled contactless GSR estimation in isolation or under controlled conditions, often with unsynchronised devices \cite{ref7}. For instance, thermal cameras and wearable GSR sensors have typically been used independently, with any data fusion done post hoc. This piecemeal approach complicates machine learning model development, since models require well-aligned datasets of inputs (e.g., video or thermal data) and outputs (measured GSR). Clearly, a multi-modal data collection platform is needed to record GSR and other sensor modalities simultaneously with proper synchronisation. Such a platform would allow researchers to gather rich, time-aligned datasets. For example, thermal video of a participant's palm could be recorded in sync with their GSR signal. These combined data would lay the groundwork for training and validating models that infer GSR from camera-based sensors. The primary contribution of this thesis is the development of just such a platform: a modular, multi-sensor system for synchronised physiological data acquisition designed for future GSR prediction research. In summary, this work is motivated by recent trends in physiological computing and multimodal sensing, and by the need for robust, synchronised datasets to advance contactless GSR measurement.


\section{Research Problem and Objectives}
The research problem is that there is no available system to synchronously collect GSR signals with complementary data streams (like thermal and visual data) in naturalistic settings, limiting machine learning models for contactless GSR prediction. Traditional GSR sensors offer reliable data but are intrusive, while fully contactless methods remain unvalidated or inaccurate \cite{ref8}. Addressing this requires a platform that simultaneously records multiple modalities \textemdash, such as a wearable sensor for skin conductance alongside thermal and visual data. All data must be tightly time-synchronised for meaningful correlation and learning. The absence of such an integrated system is the core problem this thesis attempts to address.

The objective of this research is to design and implement a multi-modal physiological data collection platform to create a synchronised dataset for future GSR prediction models. Unlike end-user applications or final predictive systems, this work focuses on the data acquisition infrastructure, essentially building the foundation on which real-time GSR inference algorithms can be developed later. Note that real-time GSR prediction is outside the scope of this thesis. Instead, the project aims to facilitate future machine learning by providing a robust way to gather ground-truth GSR and candidate predictor signals together. The following specific objectives have been defined to achieve this aim:

\subsection{Multi-Modal Platform Development} Design and develop a modular data acquisition system capable of recording synchronised physiological and imaging data. This involves integrating a wearable GSR sensor and camera-based sensors into one platform. In practice, the system uses a research-grade Shimmer3 GSR+ sensor \cite{ref8} for ground-truth skin conductance, a Topdon TC001 thermal camera \cite{ref20} attached to a smartphone for thermal video, and the smartphone's built-in RGB camera for high-resolution video. A smartphone-based sensor node will be coordinated with a desktop controller to start and stop recordings in unison and to timestamp all data consistently. The architecture should ensure that all modalities are recorded simultaneously with millisecond-level alignment.

\subsection{Synchronised Data Acquisition and Management} Implement methods for precise time synchronisation and data handling across devices. A custom control and synchronisation layer (in Python) will coordinate the sensor node(s) and ensure that GSR readings, thermal frames, and RGB frames are all logged with synchronised timestamps. This includes establishing a reliable communication protocol between the smartphone and the PC controller to transmit control commands and streaming data \cite{ref9}. Data management is also addressed: multi-modal data will be stored in appropriate formats with metadata for easy combination and analysis. The outcome should be a well-synchronised dataset (e.g., physiological sample timestamps aligned with video frame times) that can serve as a training corpus for machine learning.

\subsection{System Validation through Pilot Data Collection} Evaluate the integrated platform's performance and data integrity in a real recording scenario. Test recording sessions will be conducted to verify that the system meets research-grade requirements. For example, pilot experiments may involve human participants performing tasks designed to elicit varying GSR responses (stress, stimuli, etc.) while the platform records all modalities. Validation will focus on temporal synchronisation accuracy (e.g., confirming events are correctly aligned across sensor streams) and the quality of the recorded signals (e.g., GSR signal-to-noise ratio, thermal image resolution). The collected data will be analysed to ensure that GSR signals and corresponding thermal/RGB data show expected correlations or time-locked changes. Successful validation will demonstrate that the platform can reliably capture synchronised multi-modal data suitable for subsequent machine learning analysis. (Developing the predictive model itself is left for future work; here, the focus is on validating the data pipeline that would feed such a model.)


This thesis presents a multi-sensor data collection platform that addresses current gaps. It enables researchers to create multimodal datasets for GSR prediction, advancing contactless, real-time stress monitoring. The project features a flexible, extensible setup \textemdash a modular sensing system \textemdash that integrates the GSR sensor and thermal/RGB cameras, allowing future modality expansions. This work establishes a foundation for future studies to train and test machine learning algorithms to estimate GSR from camera data, resolved by acquiring synchronised ground-truth data.


\section{Thesis Outline}
This thesis comprises six chapters, progressing logically from background concepts to system development and evaluation:

\subsection{Background and Research Context} Reviews relevant literature and technical background. It covers physiological computing and emotion recognition, the importance of GSR in stress research, and prior approaches to contactless physiological measurement. Key related works in \textbf{multimodal data collection} and sensor fusion are examined to show the state of the art and the gap addressed by this research. The chapter also explains the rationale for choosing the specific sensors (Shimmer3 GSR+ and Topdon thermal camera) and the expected advantages of a multimodal approach.

\subsection{Requirements Analysis} Defines the specific requirements for the data collection platform. The research problem is analysed to derive both \textbf{functional requirements} (e.g., the ability to record multiple streams concurrently, synchronisation accuracy, user interface needs) and \textbf{non-functional requirements} (e.g., system reliability, timing precision, data storage considerations). Use-case scenarios and user stories illustrate these requirements in practical research situations. By the end of this chapter, the scope of the system and the criteria for success are clearly established.

\subsection{System Design and Architecture:} Describes the design of the proposed multi-modal recording system, presenting the overall \textbf{architecture} and how hardware and software components interact. Key design decisions are discussed (e.g., choosing a distributed setup with an Android smartphone as a sensor hub and a PC as the central controller \cite{ref9}). The chapter details how the \textbf{hardware integration} is achieved (mounting the thermal camera on the phone, Bluetooth pairing with the GSR sensor, etc.) and how the software is structured into modules for camera capture, sensor communication, network synchronisation, and data logging. Diagrams illustrate the flow of data and control commands between the Android app and the Python desktop application. The design emphasises modularity, so each sensing component (thermal, RGB, GSR) operates in sync under the coordination of the central controller. Important considerations such as timestamp synchronisation, latency handling, and error recovery are also described.

\subsection{Evaluation and Testing:} Documents the testing methodology, implementation, and results for the multi-sensor recording system. The testing covers unit tests, integration tests, and system-level performance evaluation. Unit tests on Android (JUnit/Robolectric) and PC (pytest/unittest) verify functionality, including error handling and security features. Integration tests use a DeviceSimulator and a JSON-based message protocol (with optional TLS) to validate multi-device synchronisation. System performance is evaluated through 8-hour endurance testing, memory leak detection (via linear regression analysis), and CPU/throughput monitoring with resource utilisation tracking. The results confirm that the system meets its functionality, reliability, and performance requirements, demonstrating research-grade reliability for scientific data collection. This validation shows the platform's capability as a data collection tool for future GSR prediction research. Any observed limitations (e.g., minor synchronisation offsets or sensor noise issues) are noted to guide future improvements.

\subsection{Conclusion and Future Work:} Summarises the thesis contributions and reflects on how well the objectives were achieved. It highlights the success of developing the multi-modal data collection platform and discusses its significance for the research community. The chapter also addresses the current system's limitations (e.g., lack of real-time analysis or untested environments). Finally, it outlines future work and recommendations, including next steps like using the collected data to train GSR prediction models, improving the platform's real-time capabilities, and extending the system with additional sensors (such as heart rate or respiration) to broaden its application. These future directions provide a roadmap for moving from this data collection foundation toward full-fledged \textbf{real-time GSR inference} in subsequent research.
