\documentclass{report}
\usepackage{amsmath} % For mathematical symbols
\usepackage{geometry} % For page layout
\usepackage[hidelinks]{hyperref} % For clickable links

\geometry{a4paper, margin=1in}

\begin{document}

    \chapter{Background and Literature Review}
    \label{ch:background}


    \section{Emotion Analysis Applications}
    \label{sec:emotion_apps}

    Automated emotion detection using physiological signals has demonstrated practical value in controlled laboratory settings. Boucsein (2012) documented extensive use of galvanic skin response (GSR) for measuring emotional arousal, particularly in studies where self-reported measures prove unreliable \cite{boucsein2012}. Jangra et al. (2021) analysed GSR applications across psychology and neuropsychology, noting its sensitivity to unconscious arousal responses that participants cannot easily suppress \cite{jangra2021}. In therapy settings, Chen et al. (2019) found that GSR patterns during cognitive behavioural therapy sessions correlated with treatment outcomes, suggesting practical utility beyond laboratory experiments \cite{chen2019}.

    Multi-modal approaches combining physiological and visual signals have shown promise for robust emotion recognition. Zhang et al. (2021) demonstrated that thermal facial imaging combined with traditional biosensors improved stress detection accuracy to 87.9\%, significantly higher than single-modality approaches \cite{zhang2021}. Similarly, studies using RGB cameras for remote photoplethysmography have achieved heart rate detection within $2$--$3$~BPM of ground truth measurements under controlled lighting conditions.

    The current platform integrates a Shimmer3 GSR+ sensor (128~Hz, 16-bit resolution) with a Topdon TC-series thermal camera ($256 \times 192$~pixels, 25~Hz) and RGB video (30~fps) to capture synchronised physiological and thermal responses. Hardware timestamps align data streams within 21~ms median offset using Network Time Protocol synchronisation. This configuration targets real-time stress assessment during controlled laboratory tasks, specifically Stroop colour-word conflict tests and Trier Social Stress Test (TSST) protocols, where ground-truth GSR can be collected simultaneously with contactless thermal and visual data for supervised learning.


    \section{Rationale for Contactless Physiological Measurement}
    \label{sec:rationale_contactless}

    Contact-based GSR measurement using conventional finger electrodes can introduce measurement artifacts. Boucsein (2012) documented how electrode attachment and wire movement creates motion artifacts in GSR data, particularly problematic during dynamic tasks \cite{boucsein2012}. Zhang et al. (2021) quantified this effect, showing that wired GSR sensors introduced movement-related noise spikes exceeding $2~\mu$S in 23\% of recorded sessions during cognitive tasks \cite{zhang2021}. Thermal imaging offers an alternative approach that avoids these contact-based limitations.

    Recent studies demonstrate practical feasibility of contactless physiological monitoring. The RTI International thermal imaging study (2024) measured nasal temperature changes during mental effort tasks, finding $0.3$--$0.7^{\circ}$C cooling responses that correlated with cognitive load ($r = 0.68$) \cite{rti2024}. Zhang et al. (2021) achieved 89.7\% accuracy in stress classification using a FLIR Lepton 3.5 thermal camera ($160 \times 120$ resolution, 9~Hz) combined with facial region-of-interest temperature tracking \cite{zhang2021}. However, these studies typically used higher-resolution thermal cameras or controlled laboratory conditions.

    Current platform specifications address known limitations in prior contactless work. The Topdon TC-series camera provides $256 \times 192$ pixel thermal resolution at 25~Hz, offering better temporal resolution than the 9~Hz FLIR devices used in previous studies. Radiometric temperature data ($\pm 0.1^{\circ}$C accuracy) enables precise measurement of the nose-tip cooling responses documented by RTI International. RGB video at 30~fps captures concurrent facial expressions for multimodal analysis, while the Shimmer3 GSR+ sensor (128~Hz sampling, $10$~k$\Omega$ to $4.7$~M$\Omega$ range) provides ground truth electrodermal activity for supervised learning.

    The goal is predicting GSR levels from thermal and RGB features during controlled stress induction protocols. Unlike previous studies that focused on binary stress classification, this approach targets continuous GSR prediction to enable real-time stress level estimation rather than simple stressed/not-stressed categorization.


    \section{Definitions of "Stress" (Scientific vs. Colloquial)}
    \label{sec:stress_definitions}

    Scientific stress research faces definitional complexity that affects measurement interpretation. Hans Selye's foundational definition of stress as ``the nonspecific result of any demand upon the body'' encompasses physiological responses to both harmful and beneficial challenges \cite{selye11}. However, this broad definition creates measurement ambiguity: elevated GSR could indicate excitement, anxiety, cognitive effort, or pain. Chen et al. (2019) documented this problem in their stress susceptibility study, noting that sympathetic nervous system activation occurred during both positive and negative emotional states \cite{chen2019}.

    Current stress measurement faces competing theoretical frameworks. The Selye model emphasizes physiological response mechanisms (HPA axis, sympathetic arousal), while psychological stress models focus on cognitive appraisal and coping resources. Lazarus and Folkman's transactional model argues that stress results from person--environment interactions rather than simple stimulus-response patterns. These theoretical differences matter for GSR interpretation: a cognitive load task might produce similar GSR responses to an anxiety-inducing stimulus, but the underlying stress mechanisms differ.

    Measurement implications for this study: GSR responses during controlled stress induction (Stroop tasks, TSST protocols) reflect acute sympathetic activation rather than chronic stress states. The platform measures phasic GSR responses (skin conductance responses, SCRs) that occur $1$--$5$ seconds after stimulus presentation, not tonic stress levels. Ground truth stress classification relies on standardized laboratory stressors with established physiological response profiles rather than subjective stress self-reports. This approach sidesteps definitional ambiguity by focusing on measurable autonomic responses to controlled stimuli, though it limits generalizability to real-world stress experiences where cognitive appraisal varies significantly across individuals and contexts.


    \section{Cortisol vs. GSR as Stress Indicators}
    \label{sec:cortisol_vs_gsr}

    Cortisol measurement challenges make it unsuitable for real-time stress monitoring. Patel et al. (2024) documented cortisol response timing in controlled laboratory stress tests: salivary cortisol peaked $22.3 \pm 6.7$ minutes after Trier Social Stress Test onset, with detection requiring enzyme immunoassay analysis \cite{patel2024}. Laboratory processing time ranges $2$--$4$ hours for standard cortisol assays, preventing real-time feedback. Chen et al. (2019) noted additional complications: circadian cortisol variation ($3$-fold morning to evening differences), individual response variability ($30$-fold between subjects), and confounding factors including caffeine, sleep, and recent meals \cite{chen2019}.

    GSR temporal characteristics enable immediate stress detection. Shimmer sensor documentation specifies GSR response latency: skin conductance changes occur $1$--$3$ seconds after stimulus presentation with a typical response duration of $5$--$15$ seconds \cite{shimmerdoc8}. The Shimmer3 GSR+ samples at 128~Hz with 16-bit resolution, capturing both tonic skin conductance level (SCL) and phasic skin conductance responses (SCRs). Patel et al. (2024) measured GSR responses during cognitive stress tasks, finding SCR amplitudes of $0.15$--$0.8~\mu$S with peak latencies of $2.1 \pm 0.4$ seconds after stimulus presentation \cite{patel2024}.

    Practical measurement differences affect experimental design. Cortisol requires participant saliva collection via passive drool ($2$--$3$~mL minimum) or Salivette tubes, followed by laboratory analysis using competitive enzyme immunoassay. Boucsein (2012) documented GSR measurement requirements: electrode gel application, $5$-minute baseline recording, and continuous monitoring throughout experimental sessions \cite{boucsein2012}. The Shimmer GSR+ uses Ag/AgCl electrodes with 0.5\% saline gel, measuring skin resistance across two finger sites (typically index and middle finger).

    Response correlation varies by stressor type and individual characteristics. Patel et al. (2024) found moderate correlation ($r = 0.43, p < 0.01$) between peak GSR amplitude and cortisol area-under-curve during TSST protocols, but this relationship weakened during cognitive tasks ($r = 0.22, p > 0.05$) \cite{patel2024}. The current platform focuses on GSR prediction because its immediate response enables real-time stress assessment, though cortisol validation could strengthen future work by confirming HPA axis activation during thermal signature collection.


    \section{GSR Physiology and Measurement Limitations}
    \label{sec:gsr_physiology}

    Shimmer3 GSR+ sensor specifications define measurement capabilities and limitations. The device uses a constant voltage method (0.5V across Ag/AgCl electrodes) measuring skin resistance from $10$~k$\Omega$ to $4.7$~M$\Omega$ with 16-bit resolution ($76~\mu\Omega$ resolution) \cite{shimmerdoc8}. Sampling at 128~Hz captures skin conductance response (SCR) dynamics, which typically have rise times of $1$--$3$ seconds and recovery times of $5$--$15$ seconds. The sensor measures resistance between two finger electrodes connected via shielded leads to minimize electromagnetic interference.

    Observed measurement limitations during preliminary testing affect data quality. Motion artifacts occur when finger movement changes electrode contact pressure; accelerometer data from the Shimmer unit shows movement events correlate with GSR spikes $>2~\mu$S that exceed physiological SCR amplitudes (typically $0.1$--$0.8~\mu$S for stress responses). Environmental temperature variations of $\pm 2^{\circ}$C change baseline skin conductance by $15$--$25$\%, requiring temperature logging and baseline normalisation. Electrode gel drying over $45$--$60$ minute sessions causes conductance drift and signal attenuation.

    Individual response variability challenges cross-participant modelling. Boucsein (2012) documented $5$--$10$\% of participants as ``non-responders'' with SCR amplitudes $<0.05~\mu$S even during strong stimuli \cite{boucsein2012}. Baseline skin conductance levels range $2$--$40~\mu$S across individuals, requiring subject-specific normalisation. Age correlates negatively with GSR responsiveness ($r = -0.34$), while skin hydration and medication use (particularly beta-blockers) affect response magnitude.


    \section{Thermal Cues of Stress in Humans}
    \label{sec:thermal_cues}

    Quantified thermal stress responses have been documented using high-resolution thermal cameras. Zhang et al. (2021) measured nasal temperature changes during cognitive stress tasks using a FLIR A655sc camera ($640 \times 480$ pixels, $0.02^{\circ}$C sensitivity), finding average nose-tip cooling of $0.47 \pm 0.23^{\circ}$C during Stroop task performance (n=32 participants) \cite{zhang2021}. RTI International (2024) documented similar responses with a FLIR One Pro camera, measuring $0.3$--$0.7^{\circ}$C nasal cooling that correlated with subjective stress ratings ($r = 0.68, p < 0.001$) \cite{rti2024}. These studies establish measurable effect sizes for stress-induced thermal changes.

    Current platform specifications enable detection of documented thermal stress signatures. The Topdon TC-series camera provides $256 \times 192$ pixel resolution with $\pm 0.1^{\circ}$C radiometric accuracy across the $8$--$14~\mu$m wavelength range. At 25~Hz frame rate, the camera captures thermal response dynamics with sufficient temporal resolution to track vasoconstriction onset (typically $2$--$5$ seconds post-stimulus). Radiometric data output enables pixel-level temperature quantification rather than qualitative thermal imaging, supporting automated feature extraction for machine learning.

    Specific thermal stress indicators target measurable physiological responses. Nose-tip region-of-interest (ROI) tracking focuses on documented vasoconstriction responses in the nasal alae and tip. Periorbital ROI monitoring captures forehead warming documented in sympathetic activation studies. Temperature gradient analysis between nose and forehead regions quantifies the characteristic cooling--warming pattern during stress responses. Breathing thermal signatures around the nostrils provide respiratory rate estimation from exhaled air temperature cycles.

    Environmental controls address thermal imaging challenges in laboratory settings. Ambient temperature maintained at $22 \pm 1^{\circ}$C prevents thermoregulatory confounds. Controlled lighting (LED panels, minimal infrared emission) avoids thermal interference. Face positioning at $0.8$--$1.2$ metre distance from camera ensures adequate spatial resolution (nose ROI spans $8$--$12$ pixels). Pre-session thermal baseline recording (2 minutes) establishes individual temperature ranges before stress testing.

    Validation approach compares thermal features with synchronised GSR responses. Thermal ROI temperature changes during identified GSR peaks establish ground truth correlations for supervised learning. Cross-validation tests thermal-only stress detection against GSR-validated stress events, targeting prediction accuracy improvements over baseline RGB-only approaches documented in prior studies (78.3\% accuracy from smartphone cameras).


    \section{RGB vs. Thermal Imaging for Stress Detection (Machine Learning Hypothesis)}
    \label{sec:rgb_vs_thermal}

    Documented performance baselines establish comparison targets for multimodal stress detection. Zhang et al. (2021) achieved 87.9\% stress classification accuracy using thermal-only features from a FLIR A655sc camera during laboratory stress tasks \cite{zhang2021}. RGB-only approaches using facial expression analysis typically reach $65$--$75$\% accuracy in controlled settings. The current platform tests whether combining $256 \times 192$ thermal data with $1920 \times 1080$ RGB video improves GSR prediction accuracy beyond these single-modality baselines.

    RGB video specifications capture behavioural and contextual stress indicators. The smartphone camera records at 30~fps with autofocus and automatic exposure control. Facial landmark detection using \texttt{MediaPipe} identifies 468 facial points for expression analysis. Remote photoplethysmography (rPPG) extraction from cheek and forehead regions estimates heart rate using green-channel pixel intensity variations. However, RGB analysis faces limitations: voluntary expression control, lighting sensitivity, and motion artifacts from head movement.

    Thermal imaging advantages target involuntary physiological responses. The Topdon TC camera's radiometric mode outputs calibrated temperature values ($\pm 0.1^{\circ}$C accuracy) rather than qualitative thermal images. Nose-tip ROI tracking captures documented vasoconstriction responses independent of facial expression control. Breathing rate estimation from nostril temperature cycles provides additional autonomic indicators. Thermal imaging performs consistently across lighting conditions and cannot be voluntarily controlled by participants.

    Synchronisation approach enables temporal feature alignment between modalities. Hardware timestamps from both cameras sync via Network Time Protocol to within 21~ms median offset. Cross-correlation analysis of breathing signals from both thermal (nostril temperature cycles) and RGB (chest movement detection) validates synchronisation accuracy. Frame-level alignment uses shared event markers (LED flash visible in RGB, thermal heating from LED) to correct any remaining temporal offset.

    Hypothesis validation tests complementary information combination. Initial analysis compares GSR prediction accuracy using thermal-only features (nose temperature, breathing rate) versus RGB-only features (facial expressions, rPPG heart rate) versus combined feature sets. Ground truth GSR events (SCR amplitude $>0.1~\mu$S) provide supervised learning targets. Cross-validation tests whether multimodal fusion exceeds best single-modality performance by statistically significant margins ($p < 0.05$).


    \section{Comparative Platforms and Open-Source Toolkits for Physiological Data Collection}
    \label{sec:platforms}

    Our platform design draws on several open-source systems that emphasize synchronization, modularity, and precise stimulus control:

    \begin{itemize}
        \item \textbf{PhysioKit:} An open-source physiological computing toolkit offering a modular acquisition pipeline and validated sensor integration \cite{physiokit}. Its design employs a microcontroller-based sensing layer and a software layer with real-time visualization and ML-driven signal quality checks \cite{physiokit}. This architecture---emphasizing modularity and synchronized multi-sensor acquisition---inspired our approach. For example, like PhysioKit, our system uses separate modules for each sensor type and implements real-time monitoring of data quality. PhysioKit's support for synchronized, co-located multi-user recording \cite{physiokit} reinforces our focus on tightly aligning data streams (GSR, thermal, RGB) in time.

        \item \textbf{iBVP Dataset Methodology (Electronics 2024):} The iBVP dataset is a structured multimodal database of synchronized RGB and thermal face videos aligned with ear-PPG signals \cite{ibvp}. Importantly, each signal in iBVP is annotated with per-sample quality labels (both manual and ML-predicted) across varied conditions (rest, easy/difficult tasks, head movement) \cite{ibvp}. This rigorous methodology highlights the value of carefully synchronized data and high-resolution annotation. We adopt its principles by designing experiments with precise timing protocols and by annotating our collected streams for quality. While iBVP focuses on facial imaging, it motivates our extension to a palm-based dataset: the palm (or hand) often provides stronger PPG signals and can be more easily oriented toward a smartphone camera than the face, potentially yielding robust multimodal data. Following iBVP's example, a future ``palm-based BVP'' dataset would collect thermal+RGB of the palm synchronized with contact PPG, using detailed quality labeling to maximize data utility.

        \item \textbf{PsychoPy:} An open-source environment for experiment control that ensures high-precision stimulus timing \cite{psychopy}. PsychoPy's timing accuracy (sub-millisecond on modern hardware) and automatic logging of exact stimulus onset times \cite{psychopy} are crucial for aligning stimuli with physiological recordings. We built our Stroop and math tasks using PsychoPy, leveraging its routines to present stimuli and record event timings. The precise log file of PsychoPy provides reliable timestamps for each trial, allowing us to synchronize task events with GSR and camera data. In practice, our code uses PsychoPy's frame-based timing and triggers so that each stimulus onset is marked and later aligned with the biosignal streams.

        \item \textbf{LabStreamingLayer (LSL):} A framework for unified, time-synchronized collection of multimodal data streams \cite{lsl}. LSL's architecture (with networked ``outlets'' and a shared clock) influenced our design of timestamped data channels. We emulate LSL's approach by treating each sensor (GSR, thermal, RGB) as a timestamped stream. However, we did not use LSL libraries directly in our Android-based system (building LSL for Android requires complex \texttt{NDK} compilation \cite{lsl}). Instead, our architecture uses standard network time protocol (NTP) to align clocks across devices and merges streams on a central host, effectively achieving LSL-like synchronization without its full middleware stack. In summary, we maintain LSL's emphasis on common timestamps and synchronized collection, even though we rely on simpler Android-compatible methods for implementation.
    \end{itemize}

    Collectively, these tools guided our architecture: emphasizing modular sensor integration (PhysioKit), structured multimodal dataset planning (iBVP), precise stimulus-timing (PsychoPy), and unified synchronization principles (LSL). In the next section, we examine our chosen sensors and devices -- the Shimmer3 GSR+ and Topdon TC thermal camera -- and explain how their characteristics align with these design principles.


    \section{Sensor Device Selection Rationale (Shimmer GSR Sensor and Topdon Thermal Camera)}
    \label{sec:sensor_selection}

    To implement the multi-modal platform described, hardware components were carefully selected that balance signal quality, integration capability, and practical considerations. In particular, the design chose the Shimmer3 GSR+ wearable sensor for electrodermal activity measurement and the Topdon TC-series thermal camera for infrared imaging, alongside a standard smartphone camera for RGB video. This section explains why these devices were chosen over alternatives, and how their characteristics support the system's goals.

    \subsection*{Shimmer3 GSR+ Sensor}
    The Shimmer3 GSR+ is a research-grade wireless sensor designed specifically for capturing GSR (EDA) along with other signals like photoplethysmography (PPG) and motion. Several key factors motivated this choice:
    \begin{itemize}
        \item \textit{High-Quality GSR Data:} The Shimmer GSR+ provides a high sampling rate and resolution for GSR. It samples at 128~Hz with 16-bit resolution on the GSR channel \cite{shimmerdoc8}, which is well above the minimum needed to capture fast SCR dynamics. The wide measurement range ($10$~k$\Omega$ to $4.7$~M$\Omega$ skin resistance) covers the full spectrum of likely skin conductance values \cite{shimmerdoc8}. This ensures that both very small responses and large sweats are recorded without clipping. Many cheaper GSR devices (e.g. those in fitness wearables) sample at lower rates or with $8$--$10$ bit ADCs, potentially missing subtle features. Shimmer's data quality is evidenced by its common use in academic research and validation studies.

        \item \textit{Multi-Channel Capability:} Although GSR is the primary interest, the Shimmer3 GSR+ includes additional sensing channels -- notably a PPG channel (for heart rate) sampled at 128~Hz, and an inertial sensor package (accelerometer, gyroscope, etc.) \cite{shimmerapi15}. These extra channels add value: the PPG can be used to derive heart rate and heart rate variability, providing another stress indicator alongside GSR \cite{shimmerapi15}. The accelerometer/gyro can be used to detect motion artifacts or estimate activity level. Instead of needing separate devices for these signals, the Shimmer offers them in one unit, time-synchronised. In the implementation, the accelerometer is enabled to log motion, which helps in data cleaning (e.g. if a participant moves suddenly and a GSR spike occurs, motion can be attributed as the cause). Having all these streams time-aligned from one device simplifies data integration.

        \item \textit{Bluetooth Wireless Connectivity:} The Shimmer connects via Bluetooth, transmitting data in real time to a host (PC or smartphone). This wireless operation was crucial for the use case -- it allows the participant to move naturally without being tethered, and it enables the sensor data to be synchronised easily with other mobile devices (like an Android phone running the cameras). The Shimmer's Bluetooth interface is supported by an official API. In the system architecture, a \texttt{ShimmerManager} module on the PC (and optionally on Android) handles connecting to the Shimmer and streaming its data \cite{shimmerapi15}. We enabled the Bluetooth interface to integrate Shimmer data seamlessly into the multi-device recording sessions. The alternative, a wired GSR device, would limit movement and complicate simultaneous recording with cameras.

        \item \textit{Open SDK and Integration:} Shimmer provides open-source APIs (for Java/Android and for Python/C++) which allowed us to integrate the sensor without reverse-engineering proprietary formats. The system leverages the Shimmer Java Android API on the mobile side and a \texttt{PyShimmer} library on the PC side \cite{shimmerapi15}. This saved significant development time. For example, the Android app includes a \texttt{ShimmerRecorder} component that interfaces with the Shimmer over Bluetooth and streams data into the recording session \cite{shimmerapi15}. The PC controller includes a \texttt{ShimmerManager} that can manage multiple Shimmer devices and coordinate their data with incoming camera data \cite{shimmerapi15}. Using the official Shimmer libraries (developed by Shimmer's engineers) proved more reliable than trying to use a generic BLE interface or a custom-built GSR device.

        \item \textit{Validated Performance:} The Shimmer3 GSR+ has been validated in prior studies, which gave us confidence in its accuracy. Its measurement technique (constant voltage across two electrodes to measure skin resistance) and internal calibration are documented in the literature, meaning the results can be compared with other research using Shimmer. This is preferable to using a novel or untested GSR device where independent validation of outputs would be required. Additionally, the Shimmer is safe and comfortable (it uses very low excitation currents for GSR to avoid any sensation). Given that participants might wear it for extended sessions, a well-designed, lightweight ($\sim$22~g) device is important \cite{shimmerdoc8}.

        \item \textit{Alternatives Considered:} We considered devices like the Empatica E4 wristband, which measures GSR, PPG, and motion. While the E4 is convenient (worn on the wrist), it has a much lower GSR sampling rate ($\sim$4~Hz) and provides only processed, cloud-synced GSR data, making real-time integration difficult. Other custom-built options (e.g. Arduino-based GSR sensors) lacked the precision and would have required solving wireless and data sync challenges ourselves. Given these trade-offs, Shimmer was the clear choice for high-quality data and integration capabilities.
    \end{itemize}

    \subsection*{Topdon Thermal Camera (TC Series)}
    For the thermal imaging component, we selected a Topdon USB thermal camera (specifically the \textit{Topdon TC001} model, a smartphone-compatible IR camera) over other thermal camera options. Several reasons justify this:
    \begin{itemize}
        \item \textit{Smartphone Integration:} The Topdon camera is designed to plug into an Android smartphone via USB-C and comes with an Android SDK. This aligns perfectly with the system architecture: the design wanted the thermal camera to be part of a mobile setup, leveraged by an Android app. Using a smartphone-based thermal camera means the system can use the phone's processing power to handle image capture (and even some preliminary processing), and it simplifies participant setup (just attach the small camera to the phone). In contrast, many high-end thermal cameras (e.g. FLIR A65 or T-series) are standalone devices requiring a PC connection (via Ethernet/USB) and a dedicated power source--- not portable for the needs. The Topdon essentially turns the phone into a thermal imaging device.

        \item \textit{Resolution and Frame Rate:} The Topdon TC camera offers a thermal sensor resolution of $256 \times 192$ pixels with a frame rate up to 25~Hz \cite{topdon20}. This is a higher resolution than older consumer thermal cameras like the FLIR One ($160 \times 120$) or Seek Thermal ($206 \times 156$). While still lower than expensive scientific cameras (which can be $640 \times 480$ or more), $256 \times 192$ provides sufficient detail for facial thermal analysis -- one can discern features like the forehead, eyes, nose, etc. in the thermogram. The 25~Hz frame rate is near-video rate, which allows capturing dynamic changes and aligning frames reasonably well with the 30~FPS RGB video. Our \texttt{ThermalRecorder} module fixes the thermal camera to 25~FPS, which proved to be a good balance between temporal resolution and data size \cite{topdon20}. (Many lower-cost thermal devices cap at 9~Hz due to export regulations, but Topdon has clearance for 25~Hz -- a big plus for smooth signal monitoring.)

        \item \textit{Radiometric Data Access:} Importantly, the Topdon SDK provides radiometric data -- meaning the system can retrieve the actual temperature reading for each pixel, not just a false-colour image. In the implementation, the system configures the camera to output both the thermal image and a temperature matrix for each frame \cite{topdon20}. The \texttt{ThermalRecorder} splits the incoming frame bytes into an image buffer and a temperature buffer, so the system records a raw thermal matrix (with calibrated temperature values per pixel) alongside the visual representation \cite{topdon20}. This quantitative data is crucial for analysis (the system can measure, for example, that the nose is at $33.1^{\circ}$C and dropped to $32.5^{\circ}$C). Some consumer cameras only give a colour-mapped thermal image without easy access to raw values, but Topdon's software allows full access. Having the image + temperature mode enabled \cite{topdon20} means the dataset contains pixel-level temperature time series, which is ideal for training machine learning models to pick up subtle variations.

        \item \textit{Cost and Availability:} The Topdon camera is relatively affordable (on the order of a few hundred USD) and commercially available. This made it feasible to acquire and deploy for this project. High-end scientific thermal cameras like the FLIR A65 can cost an order of magnitude more and are far less portable. We needed a device that a small research lab's budget could accommodate, potentially even multiple units for multi-subject data collection. Additionally, using a widely available consumer device aligns with the vision of future applications -- if stress can be inferred via a camera that any modern smartphone can host, it increases real-world applicability. Topdon, as a newer entrant in the thermal market, provided a sweet spot of performance and cost that matched the requirements (evaluation was conducted with the FLIR One Pro, but its lower resolution and some SDK limitations made Topdon more attractive).

        \item \textit{SDK and Support:} The Topdon came with an \texttt{InfiSense IRUVC SDK} (as seen in the code imports like \texttt{com.infisense.iruvc.*}) \cite{infisense16}, which was crucial for rapid integration. Through this SDK, the system controls camera settings (emissivity, temperature range, etc.) and handles USB permissions and streaming in the Android app \cite{infisense16}. The SDK supports pulling frames via a callback -- the system uses an \texttt{IFrameCallback} interface to get each frame's byte data in real time \cite{infisense16}. Without such SDK support, integrating a raw thermal feed into the app would have been prohibitively difficult (some other cameras have only PC drivers). We also considered devices like the FLIR One Pro; while FLIR has an SDK, it is more restrictive and sometimes requires licensing. The Topdon/Infisense SDK was straightforward and had no licensing roadblocks. Our \texttt{ThermalRecorder} class was built around this SDK and runs stable recordings, including tasks like requesting USB permission from the user and handling device attach/detach events at runtime \cite{infisense16}.

        \item \textit{Synchronization and System Fit:} By using the Topdon with an Android phone, the system leverages the phone's internal clock to timestamp frames. The PC controller and phone are synchronized via Network Time Protocol (NTP) to ensure all data streams (GSR, thermal frames, RGB frames) can be aligned post-hoc with sub-millisecond precision \cite{shimmerapi15}. When connected to the PC, the phone streams timestamped thermal data in real time via a WebSocket. This distributed architecture (a PC plus one or more Android devices) was designed with this hardware setup in mind \cite{shimmerapi15}. The PC acts as a master coordinating multiple Android units (each potentially running a Topdon and phone camera). The star--mesh topology of the system means each Android device is relatively self-contained in sensing capability \cite{shimmerapi15}. The Topdon fulfilled the role of giving each Android node a powerful sensing modality (thermal) with minimal additional hardware (just a tiny camera module on the phone). The devices also work well together in practice: both are small and non-invasive, allowing a participant to be recorded in a natural posture (the Shimmer sensor is typically worn on the wrist or arm with leads to the fingers, and the Topdon camera is lightweight and attached to the phone near the face). Data from both are streamed live, and the software can inject synchronisation signals if needed -- for example, the PC can send a command to flash the phone screen or toggle an LED as a sync marker, and log that event in both data streams \cite{syncmarker21}.
    \end{itemize}

    \subsection*{References}
    See \href{references.md}{centralised references} for all sources cited in this chapter.

    \begin{thebibliography}{9}

        \bibitem{physiokit}
        PhysioKit: An Open-Source, Low-Cost Physiological Computing Toolkit for Single- and Multi-User Studies - PMC.
        \url{https://pmc.ncbi.nlm.nih.gov/articles/PMC10575364/}

        \bibitem{ibvp}
        Datasets - Prof. Youngjun Cho.
        \url{https://youngjuncho.com/datasets/}

        \bibitem{psychopy}
        Timing Issues and synchronisation --- PsychoPy v2025.2.0.
        \url{https://www.psychopy.org/general/timing/index.html}

        \bibitem{lsl}
        Introduction --- Labstreaminglayer 1.13 documentation.
        \url{https://labstreaminglayer.readthedocs.io/info/intro.html}

    \end{thebibliography}

\end{document}